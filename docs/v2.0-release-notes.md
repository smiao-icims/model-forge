# ModelForge v2.0 Release Notes

## Overview

ModelForge v2.0 is a major refactoring release focused on simplification, maintainability, and enhanced functionality. This release removes complex patterns in favor of direct, clear implementations while adding powerful new features for telemetry and flexible I/O.

## üöÄ New Features

### Telemetry & Cost Tracking
- **Token Usage Monitoring**: Track prompt, completion, and total token counts for every request
- **Cost Estimation**: Real-time cost calculation based on provider pricing
  - Special handling for GitHub Copilot with reference pricing note
- **Performance Metrics**: Request duration and response times
- **Configurable Display**: Global settings to enable/disable telemetry output
- **LangChain Integration**: Uses standard LangChain callback system

### Flexible Input/Output
- **Multiple Input Sources**:
  - Command-line via `--prompt` flag
  - File input via `--input-file`
  - Standard input (stdin) for piping
- **File Output**: Save responses directly to files with `--output-file`
- **Q&A Formatting**: Clean, readable output format for interactive use
- **Streaming Support**: Full support for piping and automation

### Settings Management
- **Global Configuration**: User-wide settings in `~/.config/model-forge/config.json`
- **Local Overrides**: Project-specific settings in `./.model-forge/config.json`
- **CLI Commands**: New `settings` command group for managing preferences
- **Telemetry Control**: Enable/disable telemetry display globally or per-command

## üèóÔ∏è Architecture Improvements

### Simplified Codebase
- **Removed Complex Decorators**: No more `@handle_errors` or `@handle_cli_errors`
- **Direct Error Handling**: Clear exceptions with context and suggestions
- **Simplified Registry**: Removed factory pattern in favor of direct if/elif logic
- **Merged Utilities**: CLI utilities merged directly into cli.py
- **Cleaner Auth**: Removed abstract base classes, using simple inheritance

### Better Error Messages
- **Contextual Information**: Every error includes relevant context
- **Actionable Suggestions**: Clear next steps for users to resolve issues
- **Consistent Format**: Unified error structure across the codebase
- **No Hidden Failures**: Direct exception raising instead of silent fallbacks

### Improved Testing
- **76% Test Coverage**: Up from ~14% in v1.0
- **Comprehensive Test Suite**: 226 tests covering all major functionality
- **TDD Approach**: All v2.0 features developed with test-first methodology
- **CI/CD Ready**: Full GitHub Actions integration

## üíª Code Examples

### Using Telemetry in Python

```python
from modelforge.registry import ModelForgeRegistry
from modelforge.telemetry import TelemetryCallback, format_metrics

# Create telemetry callback
telemetry = TelemetryCallback(provider="openai", model="gpt-4")

# Get model with telemetry
registry = ModelForgeRegistry()
llm = registry.get_llm(callbacks=[telemetry])

# Use the model
response = llm.invoke("Hello, world!")

# Access metrics
print(f"Tokens used: {telemetry.metrics.token_usage.total_tokens}")
print(f"Estimated cost: ${telemetry.metrics.estimated_cost:.6f}")
print(format_metrics(telemetry.metrics))
```

### Flexible CLI Usage

```bash
# Traditional usage
modelforge test --prompt "What is AI?"

# File-based I/O
modelforge test --input-file questions.txt --output-file answers.txt

# Pipe from other commands
echo "Explain quantum computing" | modelforge test

# Disable telemetry for this command
modelforge test --prompt "Hello" --no-telemetry

# Manage settings
modelforge settings telemetry off  # Disable globally
modelforge settings telemetry on --local  # Enable for current project
```

## üìà Migration Guide

### For Library Users

The core API remains unchanged. Existing code will continue to work:

```python
# This still works exactly as before
from modelforge.registry import ModelForgeRegistry
registry = ModelForgeRegistry()
llm = registry.get_llm()
```

To use new telemetry features, add callbacks:

```python
# Add telemetry tracking
from modelforge.telemetry import TelemetryCallback
telemetry = TelemetryCallback(provider="openai", model="gpt-4")
llm = registry.get_llm(callbacks=[telemetry])
```

### For Contributors

Key changes in v2.0:
1. **No decorators**: Raise exceptions directly
2. **Direct patterns**: Avoid complex abstractions
3. **Test first**: Write tests before implementation
4. **Clear errors**: Include context and suggestions

## üîß Technical Details

### Removed Components
- `error_handler.py` - Decorator-based error handling
- `cli_utils.py` - Merged into cli.py
- Abstract base classes in auth.py
- Factory pattern in registry.py

### New Components
- `telemetry.py` - Token usage and cost tracking
- Settings management in `config.py`
- Flexible I/O in `cli.py`
- Simplified error handling throughout

### Performance
- No performance regression from v1.0
- Telemetry adds minimal overhead (<1ms)
- Improved error messages with no runtime cost

## üôè Acknowledgments

Thanks to all contributors and users who provided feedback for v2.0. Special thanks to the ModelForge community for testing and suggestions.

## üìù Full Changelog

See [CHANGELOG.md](../CHANGELOG.md) for the complete list of changes.

---

**Note**: ModelForge v2.0 maintains full backward compatibility with v1.0 for all public APIs. The simplified architecture is an internal improvement that doesn't affect library users.
